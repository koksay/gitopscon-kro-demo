apiVersion: kro.run/v1alpha1
kind: ResourceGraphDefinition
metadata:
  name: inference.kro.run
spec:
  schema:
    apiVersion: v1alpha1
    kind: Inference
    spec:
      name: string
      model: string
      project: string
      region: string
    status:
      connectionName: ${sqlinstance.status.connectionName}
      ipAddress: ${sqlinstance.status.firstIpAddress}
  resources:
  - id: sqlinstance
    template:
      apiVersion: sql.cnrm.cloud.google.com/v1beta1
      kind: SQLInstance
      metadata:
        #annotations:
        #  cnrm.cloud.google.com/deletion-policy: abandon
        labels:
          failure-zone: ${schema.spec.region}
        name: ${schema.spec.name}
      spec:
        databaseVersion: POSTGRES_17
        region: ${schema.spec.region}
        settings:
          availabilityType: REGIONAL
          backupConfiguration:
            backupRetentionSettings:
              retainedBackups: 6
            enabled: true
            location: eu
          diskSize: 10
          diskType: PD_SSD
          maintenanceWindow:
            day: 7
            hour: 3
          tier: db-custom-2-8192
  - id: bucket
    template:
      apiVersion: storage.cnrm.cloud.google.com/v1beta1
      kind: StorageBucket
      metadata:
        name: ${schema.spec.name}-${schema.spec.project}
      spec:
        uniformBucketLevelAccess: true
        location: ${schema.spec.region}
  - id: pvc
    template:
      apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: ${schema.spec.name}
      spec:
        accessModes:
          - ReadWriteOnce
        volumeMode: Filesystem
        resources:
          requests:
            storage: 50Gi
  - id: deployment
    template:
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: ${schema.spec.name}
      spec:
        replicas: 1
        selector:
          matchLabels:
            app.kubernetes.io/name: vllm
        template:
          metadata:
            labels:
              app.kubernetes.io/name: vllm
          spec:
            containers:
            - name: vllm
              image: vllm/vllm-openai:latest
              command: ["/bin/sh", "-c"]
              args: [
                "vllm serve ${schema.spec.model}"
              ]
              env:
              - name: HF_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: hf-token-secret
                    key: token
              ports:
                - containerPort: 8000
              volumeMounts:
                - name: model-storage
                  mountPath: /root/.cache/huggingface
            volumes:
            - name: model-storage
              persistentVolumeClaim:
                claimName: ${schema.spec.name}
  - id: service
    template:
      apiVersion: v1
      kind: Service
      metadata:
        name: ${schema.spec.name}
      spec:
        selector:
          app.kubernetes.io/name: vllm
        ports:
        - protocol: TCP
          port: 8000
          targetPort: 8000
        type: ClusterIP
